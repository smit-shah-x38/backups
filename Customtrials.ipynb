{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Commonly used modules\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Images, plots, display, and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import IPython\n",
    "from six.moves import urllib\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code for loading Data\n",
    "# dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "#     directory=\"/var/trainingData/\",\n",
    "#     labels=\"inferred\",\n",
    "#     label_mode=\"int\",\n",
    "#     batch_size=32,\n",
    "#     image_size=(180, 180),\n",
    "#     shuffle=True,\n",
    "#     seed=123,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1177313 files belonging to 2002 classes.\n",
      "Using 3531 files for validation.\n",
      "Found 1177313 files belonging to 2002 classes.\n",
      "Using 353 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Assume your directory structure is:\n",
    "# main_directory/\n",
    "# ...class_a/\n",
    "# ......a_image_1.jpg\n",
    "# ......a_image_2.jpg\n",
    "# ...class_b/\n",
    "# ......b_image_1.jpg\n",
    "# ......b_image_2.jpg\n",
    "\n",
    "# Create a training dataset from the main directory with 70% of data\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  directory=\"/var/trainingData/\",\n",
    "  labels=\"inferred\",\n",
    "  label_mode=\"int\",\n",
    "  image_size=(180, 180),\n",
    "  batch_size=32,\n",
    "  shuffle=True,\n",
    "  seed=123,\n",
    "  validation_split=0.003,\n",
    "  subset=\"validation\",\n",
    ")\n",
    "\n",
    "# Create a validation dataset from the main directory with 30% of data\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  directory=\"/var/trainingData/\",\n",
    "  labels=\"inferred\",\n",
    "  label_mode=\"int\",\n",
    "  image_size=(180, 180),\n",
    "  batch_size=32,\n",
    "  shuffle=True,\n",
    "  seed=123,\n",
    "  validation_split=0.0003,\n",
    "  subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class names from the train_ds\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "# Print the class names\n",
    "print(class_names)\n",
    "\n",
    "# Get the number of labels\n",
    "num_labels = len(class_names)\n",
    "\n",
    "# Print the number of labels\n",
    "print(num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a filter function that checks if the image has a non-zero shape\n",
    "def filter_zero_images(image, label):\n",
    "  # Get the shape of the image\n",
    "  image_shape = tf.shape(image)\n",
    "  # Check if the shape is non-zero\n",
    "  non_zero = tf.math.reduce_any(image_shape > 0)\n",
    "  # Return True or False\n",
    "  return non_zero\n",
    "\n",
    "# Apply the filter function to your batch dataset\n",
    "train_ds = train_ds.filter(filter_zero_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of elements in the dataset as a tensor\n",
    "num_elements = tf.data.experimental.cardinality(train_ds)\n",
    "\n",
    "# Convert the tensor to a Python integer\n",
    "num_elements = tf.get_static_value(num_elements)\n",
    "\n",
    "# Print the number of elements\n",
    "print(num_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Get the number of images by multiplying the number of elements by the batch size\n",
    "num_images = num_elements * batch_size\n",
    "\n",
    "# Print the number of images\n",
    "print(num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# # Define a transform to convert PIL images to tensors\n",
    "# transform = transforms.ToTensor()\n",
    "\n",
    "# # Iterate through each sample in the train_dataset\n",
    "# for sample in train_dataset:\n",
    "#     # Get the image tensor from the sample\n",
    "#     image_tensor = sample[0]\n",
    "\n",
    "#     # Check if the image tensor is empty\n",
    "#     if image_tensor.numel() == 0:\n",
    "#         print(\"Empty image found!\")\n",
    "\n",
    "#     # If you want to convert the image tensor to a PIL image for further processing:\n",
    "#     # Convert the image tensor to a PIL image\n",
    "#     image_pil = transforms.ToPILImage()(image_tensor)\n",
    "\n",
    "#     # Check if the PIL image dimensions are zero\n",
    "#     width, height = image_pil.size\n",
    "#     if width == 0 or height == 0:\n",
    "#         print(\"Empty image found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom layer that wraps the resize_with_pad function\n",
    "class ResizeWithPadLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, target_height, target_width):\n",
    "    super(ResizeWithPadLayer, self).__init__()\n",
    "    self.target_height = target_height\n",
    "    self.target_width = target_width\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.image.resize_with_pad(inputs, self.target_height, self.target_width)\n",
    "\n",
    "# Create an instance of the custom layer\n",
    "resize_with_pad_layer = ResizeWithPadLayer(180, 180)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 180, 180, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 90, 90, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 90, 90, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 45, 45, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 45, 45, 32)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64800)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8294528   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2002)              258258    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,557,874\n",
      "Trainable params: 8,557,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "  # Rescale the pixel values to the range [0, 1]\n",
    "  layers.Rescaling(1./255, input_shape=(180, 180, 3)),\n",
    "  # Apply a convolutional layer with 16 filters and a 3x3 kernel\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  # Apply a max pooling layer with a 2x2 window\n",
    "  layers.MaxPooling2D(),\n",
    "  # Apply another convolutional layer with 32 filters and a 3x3 kernel\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  # Apply another max pooling layer with a 2x2 window\n",
    "  layers.MaxPooling2D(),\n",
    "  # Apply a dropout layer with a rate of 0.2 to reduce overfitting\n",
    "  layers.Dropout(0.2),\n",
    "  # Flatten the output of the previous layer\n",
    "  layers.Flatten(),\n",
    "  # Apply a dense layer with 128 units and a ReLU activation\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  # Apply another dropout layer with a rate of 0.2\n",
    "  layers.Dropout(0.2),\n",
    "  # Apply an output layer with the number of classes and a softmax activation\n",
    "  layers.Dense(2002, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with an optimizer, a loss function, and a metric\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 11:50:36.235029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [3531]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-06-27 11:50:36.235382: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [3531]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-06-27 11:50:36.726807: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_2/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - ETA: 0s - loss: 7.6096 - accuracy: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 11:50:39.847905: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [353]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-06-27 11:50:39.848204: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [353]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 4s 24ms/step - loss: 7.6096 - accuracy: 0.0011 - val_loss: 7.4945 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 7.3235 - accuracy: 0.0023 - val_loss: 7.2848 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 7.1850 - accuracy: 0.0011 - val_loss: 7.1666 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 7.1248 - accuracy: 0.0025 - val_loss: 6.7917 - val_accuracy: 0.0057\n",
      "Epoch 5/10\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 6.9998 - accuracy: 0.0054 - val_loss: 6.6476 - val_accuracy: 0.0283\n",
      "Epoch 6/10\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 6.8160 - accuracy: 0.0074 - val_loss: 6.3320 - val_accuracy: 0.0340\n",
      "Epoch 7/10\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 6.6522 - accuracy: 0.0133 - val_loss: 6.0372 - val_accuracy: 0.0538\n",
      "Epoch 8/10\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 6.3572 - accuracy: 0.0232 - val_loss: 5.5903 - val_accuracy: 0.0765\n",
      "Epoch 9/10\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 6.0038 - accuracy: 0.0413 - val_loss: 5.2549 - val_accuracy: 0.1133\n",
      "Epoch 10/10\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 5.5645 - accuracy: 0.0702 - val_loss: 4.5709 - val_accuracy: 0.1841\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.5709 - accuracy: 0.1841\n",
      "Loss:  4.570947647094727\n",
      "Accuracy:  0.18413597345352173\n"
     ]
    }
   ],
   "source": [
    "# Train the model for 10 epochs\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(val_ds)\n",
    "\n",
    "# Print the loss and accuracy\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
