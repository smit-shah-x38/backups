{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Commonly used modules\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Images, plots, display, and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import IPython\n",
    "from six.moves import urllib\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code for loading Data\n",
    "# dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "#     directory=\"/var/trainingData/\",\n",
    "#     labels=\"inferred\",\n",
    "#     label_mode=\"int\",\n",
    "#     batch_size=32,\n",
    "#     image_size=(180, 180),\n",
    "#     shuffle=True,\n",
    "#     seed=123,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume your directory structure is:\n",
    "# main_directory/\n",
    "# ...class_a/\n",
    "# ......a_image_1.jpg\n",
    "# ......a_image_2.jpg\n",
    "# ...class_b/\n",
    "# ......b_image_1.jpg\n",
    "# ......b_image_2.jpg\n",
    "\n",
    "# Create a training dataset from the main directory with 70% of data\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  directory=\"/var/trainingData/\",\n",
    "  labels=\"inferred\",\n",
    "  label_mode=\"int\",\n",
    "  image_size=(180, 180),\n",
    "  batch_size=32,\n",
    "  shuffle=False,\n",
    "  seed=123,\n",
    "  validation_split=0.95,\n",
    "  subset=\"training\",\n",
    ")\n",
    "\n",
    "# Create a validation dataset from the main directory with 30% of data\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  directory=\"/var/trainingData/\",\n",
    "  labels=\"inferred\",\n",
    "  label_mode=\"int\",\n",
    "  image_size=(180, 180),\n",
    "  batch_size=32,\n",
    "  shuffle=False,\n",
    "  seed=123,\n",
    "  validation_split=0.03,\n",
    "  subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image in train_ds:\n",
    "#     print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.map(lambda x, y: (tf.cast(x, tf.float64), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "\n",
    "# # Define the path to the directory\n",
    "# directory_path = '/var/trainingData/'\n",
    "\n",
    "# # Get a list of all subdirectories\n",
    "# subdirectories = [x[0] for x in os.walk(directory_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize lists to store image file paths and labels\n",
    "# image_paths = []\n",
    "# labels = []\n",
    "\n",
    "# # Loop over each subdirectory\n",
    "# for i, subdir in enumerate(subdirectories[1:]):  # we skip the first element as it is the root directory\n",
    "#     # Find all JPEG or JPG files in the current subdirectory\n",
    "#     files = glob.glob(subdir + '/*.jpg') + glob.glob(subdir + '/*.jpeg')\n",
    "    \n",
    "#     # Add files and labels to the lists\n",
    "#     image_paths += files\n",
    "#     labels += [i] * len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Create a dataset of image file paths and labels\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_and_preprocess_image(path, label):\n",
    "#     # Load the image\n",
    "#     image = tf.io.read_file(path)\n",
    "#     image = tf.image.decode_jpeg(image, channels=3)\n",
    "    \n",
    "#     # Resize the image\n",
    "#     image = tf.image.resize(image, [224, 224])\n",
    "    \n",
    "#     # Normalize pixel values\n",
    "#     image /= 255.0\n",
    "    \n",
    "#     return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to all elements in the dataset\n",
    "# dataset = dataset.map(load_and_preprocess_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Batch, shuffle, and prefetch\n",
    "# dataset = dataset.batch(32)\n",
    "# dataset = dataset.shuffle(buffer_size=10000)\n",
    "# dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sys.getsizeof(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(train_ds.as_numpy_iterator()))\n",
    "# print(type(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# train_df = pd.DataFrame(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class names from the train_ds\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "# Print the class names\n",
    "print(class_names)\n",
    "\n",
    "# Get the number of labels\n",
    "num_labels = len(class_names)\n",
    "\n",
    "# Print the number of labels\n",
    "print(num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a filter function that checks if the image has a non-zero shape\n",
    "# def filter_zero_images(image, label):\n",
    "#   # Get the shape of the image\n",
    "#   image_shape = tf.shape(image)\n",
    "#   # Check if the shape is non-zero\n",
    "#   non_zero = tf.math.reduce_any(image_shape > 0)\n",
    "#   # Return True or False\n",
    "#   return non_zero\n",
    "\n",
    "# # Apply the filter function to your batch dataset\n",
    "# train_ds = train_ds.filter(filter_zero_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the number of elements in the dataset as a tensor\n",
    "# num_elements = tf.data.experimental.cardinality(train_ds)\n",
    "\n",
    "# # Convert the tensor to a Python integer\n",
    "# num_elements = tf.get_static_value(num_elements)\n",
    "\n",
    "# # Print the number of elements\n",
    "# print(num_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the batch size\n",
    "# batch_size = 32\n",
    "\n",
    "# # Get the number of images by multiplying the number of elements by the batch size\n",
    "# num_images = num_elements * batch_size\n",
    "\n",
    "# # Print the number of images\n",
    "# print(num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# # Define a transform to convert PIL images to tensors\n",
    "# transform = transforms.ToTensor()\n",
    "\n",
    "# # Iterate through each sample in the train_dataset\n",
    "# for sample in train_dataset:\n",
    "#     # Get the image tensor from the sample\n",
    "#     image_tensor = sample[0]\n",
    "\n",
    "#     # Check if the image tensor is empty\n",
    "#     if image_tensor.numel() == 0:\n",
    "#         print(\"Empty image found!\")\n",
    "\n",
    "#     # If you want to convert the image tensor to a PIL image for further processing:\n",
    "#     # Convert the image tensor to a PIL image\n",
    "#     image_pil = transforms.ToPILImage()(image_tensor)\n",
    "\n",
    "#     # Check if the PIL image dimensions are zero\n",
    "#     width, height = image_pil.size\n",
    "#     if width == 0 or height == 0:\n",
    "#         print(\"Empty image found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a filter function that checks if the image has a non-zero shape or pixel values\n",
    "def filter_empty_images(image, label):\n",
    "  # Get the shape of the image\n",
    "  image_shape = tf.shape(image)\n",
    "  # Check if the shape is non-zero\n",
    "  non_zero_shape = tf.math.reduce_any(image_shape > 0)\n",
    "  # Get the sum of the pixel values of the image\n",
    "  image_sum = tf.math.reduce_sum(image)\n",
    "  # Check if the sum is non-zero\n",
    "  non_zero_sum = tf.math.not_equal(image_sum, 0)\n",
    "  # Return True or False\n",
    "  return tf.math.logical_and(non_zero_shape, non_zero_sum)\n",
    "\n",
    "# Apply the filter function to your dataset\n",
    "train_ds = train_ds.filter(filter_empty_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a custom layer that wraps the resize_with_pad function\n",
    "# class ResizeWithPadLayer(tf.keras.layers.Layer):\n",
    "#   def __init__(self, target_height, target_width):\n",
    "#     super(ResizeWithPadLayer, self).__init__()\n",
    "#     self.target_height = target_height\n",
    "#     self.target_width = target_width\n",
    "\n",
    "#   def call(self, inputs):\n",
    "#     return tf.image.resize_with_pad(inputs, self.target_height, self.target_width)\n",
    "\n",
    "# # Create an instance of the custom layer\n",
    "# resize_with_pad_layer = ResizeWithPadLayer(180, 180)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "  # Rescale the pixel values to the range [0, 1]\n",
    "  layers.Rescaling(1./255, input_shape=(180, 180, 3)),\n",
    "  # Apply a convolutional layer with 16 filters and a 3x3 kernel\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  # Apply a max pooling layer with a 2x2 window\n",
    "  layers.MaxPooling2D(),\n",
    "  # Apply another convolutional layer with 32 filters and a 3x3 kernel\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  # Apply another max pooling layer with a 2x2 window\n",
    "  layers.MaxPooling2D(),\n",
    "  # Apply a dropout layer with a rate of 0.2 to reduce overfitting\n",
    "  layers.Dropout(0.2),\n",
    "  # Flatten the output of the previous layer\n",
    "  layers.Flatten(),\n",
    "  # Apply a dense layer with 128 units and a ReLU activation\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  # Apply another dropout layer with a rate of 0.2\n",
    "  layers.Dropout(0.2),\n",
    "  # Apply an output layer with the number of classes and a softmax activation\n",
    "  layers.Dense(2002)\n",
    "])\n",
    "\n",
    "# Compile the model with an optimizer, a loss function, and a metric\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for 10 epochs\n",
    "model.fit(train_ds, epochs=30)\n",
    "\n",
    "# # Evaluate the model on the test data\n",
    "# loss, accuracy = model.evaluate(val_ds)\n",
    "\n",
    "# # Print the loss and accuracy\n",
    "# print(\"Loss: \", loss)\n",
    "# print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_big_2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
